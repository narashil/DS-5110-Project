{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "# set up the session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master('YARN')\\\n",
    "        .appName(\"DS5110_Final_Project_ED_SQUAD\") \\\n",
    "        .config(\"spark.executor.memory\", \"256g\")\\\n",
    "        .getOrCreate()\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-aw29-25a:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DS5110_Final_Project_ED_SQUAD</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fde3d19e850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/qumulo/qhome/smn7ba/ds5110/project'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas too for visualizations\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.19 ms, sys: 214 µs, total: 4.41 ms\n",
      "Wall time: 3.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import mlLib libraries for classification\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data; Create a binary flag; rename columns; Drop if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.04 ms, sys: 1.13 ms, total: 4.17 ms\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import whole data from the census\n",
    "data = spark.read.csv('/project/ds5559/ds5110_project_snoo/acs_15_19_south.csv', inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|EDUC_FLAG|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 1.95 ms, sys: 2.98 ms, total: 4.93 ms\n",
      "Wall time: 938 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#writing a user defined function to create a Educated or Not Flag - if EDUC>6 then it is 1 and if not 0\n",
    "#https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08\n",
    "def EDUCFunc(value):\n",
    "  if   value > 6: \n",
    "      return 1\n",
    "  else:\n",
    "      return 0\n",
    "\n",
    "#create the function to be applied and create a new column EDUC_FLAG\n",
    "udfsomefunc = F.udf(EDUCFunc, IntegerType())\n",
    "data = data.withColumn(\"EDUC_FLAG\", udfsomefunc(\"EDUC\"))\n",
    "#see sample data\n",
    "data.select('EDUC_FLAG').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 815 µs, sys: 2.73 ms, total: 3.54 ms\n",
      "Wall time: 5.93 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#check the count for EDUC>6 or verify if flag was populated correctly\n",
    "data.filter(data.EDUC>6).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.74 ms, sys: 2.07 ms, total: 3.82 ms\n",
      "Wall time: 7.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Verify the flag count. Should match number above\n",
    "data.filter(data.EDUC_FLAG!=0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About data\n",
    "AMERICAN COMMUNITY SURVEY 2015-2019 5-YEAR SAMPLE <br>\n",
    "5-in-100 national random sample of the population <br>\n",
    "Contains all households and persons from the 1% ACS samples for 2015, 2016, 2017, 2018, and 2019 identifiable by year. <br>\n",
    "The data include persons in group quarters. <br>\n",
    "This is a weighted sample. <br>\n",
    "The smallest identifiable geographic unit is the PUMA, containing at least 100,000 persons. PUMAs do not cross state boundaries. <br>\n",
    "Users should read the FAQ on the multi-year data. <br>\n",
    "\n",
    "\n",
    "WHERE CAN I GET BETTER GEOGRAPHIC IDENTIFIERS? <br>\n",
    "The lowest unit of geography in the microdata files is still the PUMA. PUMAs contain at least 100,000 people. <br>\n",
    "Aggregate data (but not microdata) is currently available from the Census Bureau for geographic areas as small as block groups, but only for the entire 2005-2009 period. <br>\n",
    "\n",
    "\n",
    "PERNUM numbers all persons within each household consecutively in the order in which they appear on the original census or survey form. <br>\n",
    "When combined with SAMPLE and SERIAL, PERNUM uniquely identifies each person within the IPUMS. <br>\n",
    "\n",
    "MULTYEAR identifies the actual year of survey in multi-year ACS/PRCS samples. <br>\n",
    "\n",
    "<br>\n",
    "For example, the 3-year ACS and PRCS data files each include cases from three single-year files. <br>\n",
    "For these multi-year samples, the YEAR variable identifies the last year of data (2007 for the 2005-2007 3-year data; 2008 for the 2006-2008 data; and so on). <br>\n",
    "MULTYEAR gives the single-year sample from which the case was drawn (2005, 2006, or 2007 for the 2005-2007 3-year data; 2006, 2007, or 2008 for the 2006-2008 3-year data; and so on). <br>\n",
    "\n",
    "https://usa.ipums.org/usa/acs_multyr.shtml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 252 µs, sys: 1.2 ms, total: 1.45 ms\n",
      "Wall time: 43 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#renaming dependent variable to label because the classfier is not recognizing other names. Skip thsi if you are trying other classifiers\n",
    "\n",
    "df = data.withColumn(\"label\",data.EDUC_FLAG) \\\n",
    "      .drop(\"EDUC_FLAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving col names in case if we can use it later ot iterate or use the list for labels etc.\n",
    "cols = df.columns\n",
    "#spark.createDataFrame(cols,StringType()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5965249, 206)\n"
     ]
    }
   ],
   "source": [
    "#displaying number of rows and columns in the data\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|MULTYEAR|\n",
      "+--------+\n",
      "|    2018|\n",
      "|    2015|\n",
      "|    2019|\n",
      "|    2016|\n",
      "|    2017|\n",
      "+--------+\n",
      "\n",
      "CPU times: user 1.16 ms, sys: 1.23 ms, total: 2.4 ms\n",
      "Wall time: 6.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#number of years in the data set\n",
    "df.select('MULTYEAR').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|MULTYEAR| count|\n",
      "+--------+------+\n",
      "|    2015|293037|\n",
      "|    2016|295407|\n",
      "|    2017|298937|\n",
      "|    2018|300273|\n",
      "|    2019|304384|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sampling data to use more effeciently; seed = 42\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sampleBy.html\n",
    "#https://towardsdatascience.com/exploratory-data-analysis-eda-with-pyspark-on-databricks-e8d6529626b1\n",
    "#https://www.kaggle.com/tientd95/advanced-pyspark-for-exploratory-data-analysis\n",
    "sampled = df.sampleBy(\"MULTYEAR\", fractions={2015: 0.25, 2016: 0.25, 2017:0.25, 2018:0.25, 2019:0.25}, seed=42)\n",
    "sampled.groupBy(\"MULTYEAR\").count().orderBy(\"MULTYEAR\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhhtype_dict = {'0':'N/A',            '1': 'Married-couple family household',            '2': 'Male householder, no wife present',            '3': 'Female householder, no husband present',            '4': 'Male householder, living alone',            '5': 'Male householder, not living alone',            '6': 'Female householder, living alone',            '7': 'Female householder, not living alone',            '9': 'HHTYPE could not be determined'}\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map to create meanign ful table # wip\n",
    "'''\n",
    "hhtype_dict = {'0':'N/A',\\\n",
    "            '1': 'Married-couple family household',\\\n",
    "            '2': 'Male householder, no wife present',\\\n",
    "            '3': 'Female householder, no husband present',\\\n",
    "            '4': 'Male householder, living alone',\\\n",
    "            '5': 'Male householder, not living alone',\\\n",
    "            '6': 'Female householder, living alone',\\\n",
    "            '7': 'Female householder, not living alone',\\\n",
    "            '9': 'HHTYPE could not be determined'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) ).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+\n",
      "|MULTYEAR|HHTYPE|count |\n",
      "+--------+------+------+\n",
      "|2019    |1     |183494|\n",
      "|2019    |3     |37065 |\n",
      "|2019    |6     |20111 |\n",
      "|2019    |4     |14338 |\n",
      "|2019    |2     |10785 |\n",
      "|2019    |5     |3884  |\n",
      "|2019    |7     |3201  |\n",
      "|2018    |1     |180873|\n",
      "|2018    |3     |37453 |\n",
      "|2018    |6     |19439 |\n",
      "|2018    |4     |14157 |\n",
      "|2018    |2     |10990 |\n",
      "|2018    |5     |3924  |\n",
      "|2018    |7     |3197  |\n",
      "|2017    |1     |178903|\n",
      "|2017    |3     |38048 |\n",
      "|2017    |6     |19292 |\n",
      "|2017    |4     |14011 |\n",
      "|2017    |2     |10345 |\n",
      "|2017    |5     |3998  |\n",
      "|2017    |7     |3160  |\n",
      "|2016    |1     |176609|\n",
      "|2016    |3     |37926 |\n",
      "|2016    |6     |19519 |\n",
      "|2016    |4     |13590 |\n",
      "|2016    |2     |10355 |\n",
      "|2016    |5     |3757  |\n",
      "|2016    |7     |3223  |\n",
      "|2015    |1     |174786|\n",
      "|2015    |3     |38279 |\n",
      "|2015    |6     |19423 |\n",
      "|2015    |4     |13368 |\n",
      "|2015    |2     |10081 |\n",
      "|2015    |5     |3818  |\n",
      "|2015    |7     |3045  |\n",
      "+--------+------+------+\n",
      "\n",
      "CPU times: user 3.38 ms, sys: 2.5 ms, total: 5.89 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##aggregating counts by Year and HHtype for sampple dataset - add labels - convert to visualization\n",
    "#sampled_n = sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) )\n",
    "#sampled.filter((sampled.HHTYPE!=0) & (sampled.HHTYPE!=9)).groupBy('MULTYEAR','HHTYPE').count()\\\n",
    "    #.orderBy('MULTYEAR','count', ascending=False).show(100,truncate=False)\n",
    "sampled.filter((sampled.HHTYPE!=0) & (sampled.HHTYPE!=9)).groupBy('MULTYEAR','HHTYPE').count()\\\n",
    "    .orderBy('MULTYEAR','count', ascending=False).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data; Scale; PCA; RF Classification - seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 8.94 ms, sys: 2.91 ms, total: 11.9 ms\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pass all the features into vector assembler to create a vector format to pass tto the classification model\n",
    "assembler = VectorAssembler(inputCols=[cols for cols in cols if cols!='label'], outputCol=\"features\") \n",
    "transformed = assembler.transform(sampled)\n",
    "#register table as sql table and keep only columns fo interest and save in a new dataframe. This can be done without using SQl as well.\n",
    "transformed.registerTempTable('transformed_tbl')\n",
    "transformed_df = sqlContext.sql('select label,features from transformed_tbl')\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 ms, sys: 767 µs, total: 7.04 ms\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#scale the data\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(transformed_df)\n",
    "scaledData = scalerModel.transform(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|      scaledFeatures|\n",
      "+-----+--------------------+\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 1.29 ms, sys: 815 µs, total: 2.1 ms\n",
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#check sample scaled data\n",
    "scaledData.select(\"label\",\"scaledFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 833 µs, sys: 833 µs, total: 1.67 ms\n",
      "Wall time: 92.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#randomly split data\n",
    "training_data, test_data = scaledData.randomSplit([0.7, 0.3], seed=42)\n",
    "cached_tr = training_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#pca to reduce 200 odd features into principal components - on training data only because that is our model\n",
    "#this takes a while to run. imagine it is running at least 9 combinations models with 3 folds and picking the best. Reduce parameters or folds if you want it to run faster\n",
    "pca_model = PCA(inputCol = \"scaledFeatures\", outputCol = \"pca_features_cv\")\n",
    "\n",
    "#create a randomforest classifier model to pass into pipeline\n",
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"pca_features_cv\")\n",
    "\n",
    "#creating a pipeline with the pca and model to use in the cross validator\n",
    "ppl_cv = Pipeline(stages = [pca_model, rf])\n",
    "\n",
    "\n",
    "#create a param grid to pass to cross validator \n",
    "#k --> number of principal components\n",
    "#number of treess in rf\n",
    "#need to add more later\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "  .addGrid(pca_model.k, [10, 20, 30]) \\\n",
    "  .addGrid(rf.numTrees, [20, 30, 50]) \\\n",
    "  .build()\n",
    "\n",
    "#passs the model with variosu combinations of the parameters and it will pick the best one. Using 3 folds to save time. Check seed=42.\n",
    "crossval = CrossValidator(estimator = ppl_cv,\\\n",
    "                                        estimatorParamMaps=paramGrid,\\\n",
    "                                        evaluator = MulticlassClassificationEvaluator(),\\\n",
    "                                        numFolds= 3,seed=42)\n",
    "\n",
    "\n",
    "#this is our best model - fit the training data\n",
    "cv_model = crossval.fit(cached_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ea0d78ffcba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#all the 9 model accuracies. The max one was picked as best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mavgMetricsGrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavgMetricsGrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#https://tsmatz.github.io/azure-databricks-exercise/exercise04-hyperparams-tuning.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv_model' is not defined"
     ]
    }
   ],
   "source": [
    "#all the 9 model accuracies. The max one was picked as best\n",
    "avgMetricsGrid = cv_model.avgMetrics\n",
    "print(avgMetricsGrid)\n",
    "\n",
    "#https://tsmatz.github.io/azure-databricks-exercise/exercise04-hyperparams-tuning.html\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\n",
    "# View all results (accuracy) by each params - these can be converted to pretty tables in pandas later\n",
    "list(zip(cv_model.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#predict and evaluate the model for accuracy\n",
    "predictions = cv_model.transform(test_data)\n",
    "evaluator= MulticlassClassificationEvaluator(labelCol = \"label\", metricName= \"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increased accuracy with binary flag\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix, threshold, roc and other fun stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##more to come"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without PCA but selective features and QQ variables dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References\n",
    "#https://awesomeopensource.com/project/adornes/spark_python_ml_examples\n",
    "#https://spark.apache.org/docs/latest/ml-tuning.html\n",
    "#https://sparkbyexamples.com/pyspark/pyspark-rename-dataframe-column/\n",
    "#https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\n",
    "#https://people.stat.sc.edu/haigang/sparkCaseStudy.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110",
   "language": "python",
   "name": "ds5110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
