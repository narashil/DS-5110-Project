{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "# set up the session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas too for visualizations\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mlLib libraries for classification\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data; Create a binary flag; rename columns; Drop if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import whole data from the census\n",
    "data = spark.read.csv('/project/ds5559/ds5110_project_snoo/acs_15_19_south.csv', inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|EDUC_FLAG|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#writing a user defined function to create a Educated or Not Flag - if EDUC>6 then it is 1 and if not 0\n",
    "#https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08\n",
    "def EDUCFunc(value):\n",
    "  if   value > 6: \n",
    "      return 1\n",
    "  else:\n",
    "      return 0\n",
    "\n",
    "#create the function to be applied and create a new column EDUC_FLAG\n",
    "udfsomefunc = F.udf(EDUCFunc, IntegerType())\n",
    "data = data.withColumn(\"EDUC_FLAG\", udfsomefunc(\"EDUC\"))\n",
    "#see sample data\n",
    "data.select('EDUC_FLAG').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the count for EDUC>6 or verify if flag was populated correctly\n",
    "data.filter(data.EDUC>6).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify the flag count. Should match number above\n",
    "data.filter(data.EDUC_FLAG!=0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About data\n",
    "AMERICAN COMMUNITY SURVEY 2015-2019 5-YEAR SAMPLE <br>\n",
    "5-in-100 national random sample of the population <br>\n",
    "Contains all households and persons from the 1% ACS samples for 2015, 2016, 2017, 2018, and 2019 identifiable by year. <br>\n",
    "The data include persons in group quarters. <br>\n",
    "This is a weighted sample. <br>\n",
    "The smallest identifiable geographic unit is the PUMA, containing at least 100,000 persons. PUMAs do not cross state boundaries. <br>\n",
    "Users should read the FAQ on the multi-year data. <br>\n",
    "\n",
    "\n",
    "WHERE CAN I GET BETTER GEOGRAPHIC IDENTIFIERS? <br>\n",
    "The lowest unit of geography in the microdata files is still the PUMA. PUMAs contain at least 100,000 people. <br>\n",
    "Aggregate data (but not microdata) is currently available from the Census Bureau for geographic areas as small as block groups, but only for the entire 2005-2009 period. <br>\n",
    "\n",
    "\n",
    "PERNUM numbers all persons within each household consecutively in the order in which they appear on the original census or survey form. <br>\n",
    "When combined with SAMPLE and SERIAL, PERNUM uniquely identifies each person within the IPUMS. <br>\n",
    "\n",
    "MULTYEAR identifies the actual year of survey in multi-year ACS/PRCS samples. <br>\n",
    "\n",
    "<br>\n",
    "For example, the 3-year ACS and PRCS data files each include cases from three single-year files. <br>\n",
    "For these multi-year samples, the YEAR variable identifies the last year of data (2007 for the 2005-2007 3-year data; 2008 for the 2006-2008 data; and so on). <br>\n",
    "MULTYEAR gives the single-year sample from which the case was drawn (2005, 2006, or 2007 for the 2005-2007 3-year data; 2006, 2007, or 2008 for the 2006-2008 3-year data; and so on). <br>\n",
    "\n",
    "https://usa.ipums.org/usa/acs_multyr.shtml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming dependent variable to label because the classfier is not recognizing other names. Skip thsi if you are trying other classifiers\n",
    "from pyspark.sql.functions import *\n",
    "df = data.withColumn(\"label\",col(\"EDUC_FLAG\")) \\\n",
    "      .drop(\"EDUC_FLAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving col names in case if we can use it later ot iterate or use the list for labels etc.\n",
    "cols = df.columns\n",
    "#spark.createDataFrame(cols,StringType()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5965249, 206)\n"
     ]
    }
   ],
   "source": [
    "#displaying number of rows and columns in the data\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|MULTYEAR|\n",
      "+--------+\n",
      "|    2018|\n",
      "|    2015|\n",
      "|    2019|\n",
      "|    2016|\n",
      "|    2017|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#number of years in the data set\n",
    "df.select('MULTYEAR').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|MULTYEAR|count|\n",
      "+--------+-----+\n",
      "|    2015|34940|\n",
      "|    2016|35487|\n",
      "|    2017|35961|\n",
      "|    2018|36031|\n",
      "|    2019|36488|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sampling data to use more effeciently; seed = 42\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sampleBy.html\n",
    "#https://towardsdatascience.com/exploratory-data-analysis-eda-with-pyspark-on-databricks-e8d6529626b1\n",
    "#https://www.kaggle.com/tientd95/advanced-pyspark-for-exploratory-data-analysis\n",
    "sampled = df.sampleBy(\"MULTYEAR\", fractions={2015: 0.03, 2016: 0.03, 2017:0.03, 2018:0.03, 2019:0.03}, seed=42)\n",
    "sampled.groupBy(\"MULTYEAR\").count().orderBy(\"MULTYEAR\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map to create meanign ful table # wip\n",
    "'''\n",
    "hhtype_dict = {'0':'N/A',\\\n",
    "            '1': 'Married-couple family household',\\\n",
    "            '2': 'Male householder, no wife present',\\\n",
    "            '3': 'Female householder, no husband present',\\\n",
    "            '4': 'Male householder, living alone',\\\n",
    "            '5': 'Male householder, not living alone',\\\n",
    "            '6': 'Female householder, living alone',\\\n",
    "            '7': 'Female householder, not living alone',\\\n",
    "            '9': 'HHTYPE could not be determined'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) ).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|MULTYEAR|HHTYPE|count|\n",
      "+--------+------+-----+\n",
      "|2019    |1     |22462|\n",
      "|2019    |3     |4466 |\n",
      "|2019    |6     |2421 |\n",
      "|2019    |4     |1733 |\n",
      "|2019    |2     |1333 |\n",
      "|2019    |5     |481  |\n",
      "|2019    |7     |375  |\n",
      "|2018    |1     |21907|\n",
      "|2018    |3     |4512 |\n",
      "|2018    |6     |2394 |\n",
      "|2018    |4     |1706 |\n",
      "|2018    |2     |1342 |\n",
      "|2018    |5     |463  |\n",
      "|2018    |7     |410  |\n",
      "|2017    |1     |21676|\n",
      "|2017    |3     |4582 |\n",
      "|2017    |6     |2397 |\n",
      "|2017    |4     |1669 |\n",
      "|2017    |2     |1247 |\n",
      "|2017    |5     |510  |\n",
      "|2017    |7     |391  |\n",
      "|2016    |1     |21697|\n",
      "|2016    |3     |4694 |\n",
      "|2016    |6     |2361 |\n",
      "|2016    |4     |1668 |\n",
      "|2016    |2     |1268 |\n",
      "|2016    |5     |450  |\n",
      "|2016    |7     |432  |\n",
      "|2015    |1     |21096|\n",
      "|2015    |3     |4747 |\n",
      "|2015    |6     |2367 |\n",
      "|2015    |4     |1640 |\n",
      "|2015    |2     |1272 |\n",
      "|2015    |5     |476  |\n",
      "|2015    |7     |335  |\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##aggregating counts by Year and HHtype for sampple dataset - add labels - convert to visualization\n",
    "#sampled_n = sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) )\n",
    "sampled.filter((sampled.HHTYPE!=0) & (sampled.HHTYPE!=9)).groupBy('MULTYEAR','HHTYPE').count()\\\n",
    "    .orderBy('MULTYEAR','count', ascending=False).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MULTYEAR: integer (nullable = true)\n",
      " |-- SAMPLE: integer (nullable = true)\n",
      " |-- SERIAL: integer (nullable = true)\n",
      " |-- CBSERIAL: long (nullable = true)\n",
      " |-- HHWT: double (nullable = true)\n",
      " |-- HHTYPE: integer (nullable = true)\n",
      " |-- CLUSTER: long (nullable = true)\n",
      " |-- REGION: integer (nullable = true)\n",
      " |-- STATEFIP: integer (nullable = true)\n",
      " |-- COUNTYFIP: integer (nullable = true)\n",
      " |-- METRO: integer (nullable = true)\n",
      " |-- STRATA: integer (nullable = true)\n",
      " |-- GQ: integer (nullable = true)\n",
      " |-- OWNERSHP: integer (nullable = true)\n",
      " |-- OWNERSHPD: integer (nullable = true)\n",
      " |-- MORTGAGE: integer (nullable = true)\n",
      " |-- TAXINCL: integer (nullable = true)\n",
      " |-- INSINCL: integer (nullable = true)\n",
      " |-- PROPINSR: integer (nullable = true)\n",
      " |-- COSTELEC: integer (nullable = true)\n",
      " |-- COSTGAS: integer (nullable = true)\n",
      " |-- COSTWATR: integer (nullable = true)\n",
      " |-- COSTFUEL: integer (nullable = true)\n",
      " |-- FOODSTMP: integer (nullable = true)\n",
      " |-- VALUEH: integer (nullable = true)\n",
      " |-- FRIDGE: integer (nullable = true)\n",
      " |-- CINETHH: integer (nullable = true)\n",
      " |-- CILAPTOP: integer (nullable = true)\n",
      " |-- CISMRTPHN: integer (nullable = true)\n",
      " |-- CITABLET: integer (nullable = true)\n",
      " |-- CIDATAPLN: integer (nullable = true)\n",
      " |-- CIHISPEED: integer (nullable = true)\n",
      " |-- CISAT: integer (nullable = true)\n",
      " |-- CIDIAL: integer (nullable = true)\n",
      " |-- CIOTHSVC: integer (nullable = true)\n",
      " |-- FUELHEAT: integer (nullable = true)\n",
      " |-- VEHICLES: integer (nullable = true)\n",
      " |-- COUPLETYPE: integer (nullable = true)\n",
      " |-- SSMC: integer (nullable = true)\n",
      " |-- NFAMS: integer (nullable = true)\n",
      " |-- NSUBFAM: integer (nullable = true)\n",
      " |-- NCOUPLES: integer (nullable = true)\n",
      " |-- NMOTHERS: integer (nullable = true)\n",
      " |-- NFATHERS: integer (nullable = true)\n",
      " |-- MULTGEN: integer (nullable = true)\n",
      " |-- MULTGEND: integer (nullable = true)\n",
      " |-- QCOSTELE: integer (nullable = true)\n",
      " |-- QCOSTFUE: integer (nullable = true)\n",
      " |-- QCOSTGAS: integer (nullable = true)\n",
      " |-- QCOSTWAT: integer (nullable = true)\n",
      " |-- QFOODSTM: integer (nullable = true)\n",
      " |-- QINSINCL: integer (nullable = true)\n",
      " |-- QMORTGAG: integer (nullable = true)\n",
      " |-- QOWNERSH: integer (nullable = true)\n",
      " |-- QPROPINS: integer (nullable = true)\n",
      " |-- QTAXINCL: integer (nullable = true)\n",
      " |-- QVALUEH: integer (nullable = true)\n",
      " |-- QFUELHEA: integer (nullable = true)\n",
      " |-- QCIDIAL: integer (nullable = true)\n",
      " |-- QCILAPTOP: integer (nullable = true)\n",
      " |-- QCINETHH: integer (nullable = true)\n",
      " |-- QCIOTHSVC: integer (nullable = true)\n",
      " |-- QCISAT: integer (nullable = true)\n",
      " |-- QCISMRTPHN: integer (nullable = true)\n",
      " |-- QCITABLET: integer (nullable = true)\n",
      " |-- QCIDATAPLN: integer (nullable = true)\n",
      " |-- QVEHICLE: integer (nullable = true)\n",
      " |-- RESPMODE: integer (nullable = true)\n",
      " |-- PERNUM: integer (nullable = true)\n",
      " |-- PERWT: double (nullable = true)\n",
      " |-- RELATE: integer (nullable = true)\n",
      " |-- RELATED: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARST: integer (nullable = true)\n",
      " |-- BIRTHYR: integer (nullable = true)\n",
      " |-- MARRNO: integer (nullable = true)\n",
      " |-- YRMARR: integer (nullable = true)\n",
      " |-- RACE: integer (nullable = true)\n",
      " |-- RACED: integer (nullable = true)\n",
      " |-- HISPAN: integer (nullable = true)\n",
      " |-- HISPAND: integer (nullable = true)\n",
      " |-- BPL: integer (nullable = true)\n",
      " |-- BPLD: integer (nullable = true)\n",
      " |-- CITIZEN: integer (nullable = true)\n",
      " |-- YRNATUR: integer (nullable = true)\n",
      " |-- YRIMMIG: integer (nullable = true)\n",
      " |-- YRSUSA1: integer (nullable = true)\n",
      " |-- RACAMIND: integer (nullable = true)\n",
      " |-- RACASIAN: integer (nullable = true)\n",
      " |-- RACBLK: integer (nullable = true)\n",
      " |-- RACPACIS: integer (nullable = true)\n",
      " |-- RACWHT: integer (nullable = true)\n",
      " |-- RACOTHER: integer (nullable = true)\n",
      " |-- HCOVANY: integer (nullable = true)\n",
      " |-- HCOVPRIV: integer (nullable = true)\n",
      " |-- HINSEMP: integer (nullable = true)\n",
      " |-- HINSPUR: integer (nullable = true)\n",
      " |-- HINSTRI: integer (nullable = true)\n",
      " |-- HCOVPUB: integer (nullable = true)\n",
      " |-- HINSCAID: integer (nullable = true)\n",
      " |-- HINSCARE: integer (nullable = true)\n",
      " |-- HINSVA: integer (nullable = true)\n",
      " |-- HINSIHS: integer (nullable = true)\n",
      " |-- SCHOOL: integer (nullable = true)\n",
      " |-- EDUC: integer (nullable = true)\n",
      " |-- EDUCD: integer (nullable = true)\n",
      " |-- GRADEATT: integer (nullable = true)\n",
      " |-- GRADEATTD: integer (nullable = true)\n",
      " |-- SCHLTYPE: integer (nullable = true)\n",
      " |-- DEGFIELD: integer (nullable = true)\n",
      " |-- DEGFIELDD: integer (nullable = true)\n",
      " |-- DEGFIELD2: integer (nullable = true)\n",
      " |-- DEGFIELD2D: integer (nullable = true)\n",
      " |-- EMPSTAT: integer (nullable = true)\n",
      " |-- EMPSTATD: integer (nullable = true)\n",
      " |-- LABFORCE: integer (nullable = true)\n",
      " |-- CLASSWKR: integer (nullable = true)\n",
      " |-- CLASSWKRD: integer (nullable = true)\n",
      " |-- OCC: integer (nullable = true)\n",
      " |-- IND: integer (nullable = true)\n",
      " |-- UHRSWORK: integer (nullable = true)\n",
      " |-- LOOKING: integer (nullable = true)\n",
      " |-- AVAILBLE: integer (nullable = true)\n",
      " |-- INCTOT: integer (nullable = true)\n",
      " |-- FTOTINC: integer (nullable = true)\n",
      " |-- INCWAGE: integer (nullable = true)\n",
      " |-- INCBUS00: integer (nullable = true)\n",
      " |-- INCSS: integer (nullable = true)\n",
      " |-- INCWELFR: integer (nullable = true)\n",
      " |-- INCINVST: integer (nullable = true)\n",
      " |-- INCRETIR: integer (nullable = true)\n",
      " |-- INCSUPP: integer (nullable = true)\n",
      " |-- INCOTHER: integer (nullable = true)\n",
      " |-- INCEARN: integer (nullable = true)\n",
      " |-- POVERTY: integer (nullable = true)\n",
      " |-- OCCSCORE: integer (nullable = true)\n",
      " |-- SEI: integer (nullable = true)\n",
      " |-- HWSEI: double (nullable = true)\n",
      " |-- VETSTAT: integer (nullable = true)\n",
      " |-- VETSTATD: integer (nullable = true)\n",
      " |-- VET01LTR: integer (nullable = true)\n",
      " |-- PWSTATE2: integer (nullable = true)\n",
      " |-- PWCOUNTY: integer (nullable = true)\n",
      " |-- PWTYPE: integer (nullable = true)\n",
      " |-- PWPUMA00: integer (nullable = true)\n",
      " |-- TRANWORK: integer (nullable = true)\n",
      " |-- CARPOOL: integer (nullable = true)\n",
      " |-- RIDERS: integer (nullable = true)\n",
      " |-- TRANTIME: integer (nullable = true)\n",
      " |-- DEPARTS: integer (nullable = true)\n",
      " |-- ARRIVES: integer (nullable = true)\n",
      " |-- GCHOUSE: integer (nullable = true)\n",
      " |-- GCMONTHS: integer (nullable = true)\n",
      " |-- GCRESPON: integer (nullable = true)\n",
      " |-- QAGE: integer (nullable = true)\n",
      " |-- QMARRNO: integer (nullable = true)\n",
      " |-- QMARST: integer (nullable = true)\n",
      " |-- QRELATE: integer (nullable = true)\n",
      " |-- QSEX: integer (nullable = true)\n",
      " |-- QYRMARR: integer (nullable = true)\n",
      " |-- QBPL: integer (nullable = true)\n",
      " |-- QCITIZEN: integer (nullable = true)\n",
      " |-- QHISPAN: integer (nullable = true)\n",
      " |-- QRACE: integer (nullable = true)\n",
      " |-- QYRNATUR: integer (nullable = true)\n",
      " |-- QHINSEMP: integer (nullable = true)\n",
      " |-- QHINSPUR: integer (nullable = true)\n",
      " |-- QHINSTRI: integer (nullable = true)\n",
      " |-- QHINSCAI: integer (nullable = true)\n",
      " |-- QHINSCAR: integer (nullable = true)\n",
      " |-- QHINSVA: integer (nullable = true)\n",
      " |-- QHINSIHS: integer (nullable = true)\n",
      " |-- QEDUC: integer (nullable = true)\n",
      " |-- QGRADEAT: integer (nullable = true)\n",
      " |-- QDEGFIELD: integer (nullable = true)\n",
      " |-- QSCHOOL: integer (nullable = true)\n",
      " |-- QCLASSWK: integer (nullable = true)\n",
      " |-- QEMPSTAT: integer (nullable = true)\n",
      " |-- QIND: integer (nullable = true)\n",
      " |-- QOCC: integer (nullable = true)\n",
      " |-- QUHRSWOR: integer (nullable = true)\n",
      " |-- QINCEARN: integer (nullable = true)\n",
      " |-- QINCBUS: integer (nullable = true)\n",
      " |-- QINCINVS: integer (nullable = true)\n",
      " |-- QINCOTHE: integer (nullable = true)\n",
      " |-- QINCRETI: integer (nullable = true)\n",
      " |-- QINCSS: integer (nullable = true)\n",
      " |-- QINCSUPP: integer (nullable = true)\n",
      " |-- QINCTOT: integer (nullable = true)\n",
      " |-- QFTOTINC: integer (nullable = true)\n",
      " |-- QINCWAGE: integer (nullable = true)\n",
      " |-- QINCWELF: integer (nullable = true)\n",
      " |-- QVETSTAT: integer (nullable = true)\n",
      " |-- QCARPOOL: integer (nullable = true)\n",
      " |-- QDEPARTS: integer (nullable = true)\n",
      " |-- QPWSTAT2: integer (nullable = true)\n",
      " |-- QRIDERS: integer (nullable = true)\n",
      " |-- QTRANTIM: integer (nullable = true)\n",
      " |-- QTRANWOR: integer (nullable = true)\n",
      " |-- QGCHOUSE: integer (nullable = true)\n",
      " |-- QGCMONTH: integer (nullable = true)\n",
      " |-- QGCRESPO: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data; Scale; PCA; RF Classification - seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    1|[105.0,2019.0,201...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pass all the features into vector assembler to create a vector format to pass tto the classification model\n",
    "assembler = VectorAssembler(inputCols=[cols for cols in sampled.columns if cols!='label'], outputCol=\"features\") \n",
    "transformed = assembler.transform(sampled)\n",
    "#register table as sql table and keep only columns fo interest and save in a new dataframe. This can be done without using SQl as well.\n",
    "transformed.registerTempTable('transformed_tbl')\n",
    "transformed_df = sqlContext.sql('select label,features from transformed_tbl')\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(transformed_df)\n",
    "scaledData = scalerModel.transform(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|      scaledFeatures|\n",
      "+-----+--------------------+\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    1|[2.18691054270554...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check sample scaled data\n",
    "scaledData.select(\"label\",\"scaledFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly split data\n",
    "training_data, test_data = scaledData.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca to reduce 200 odd features into principal components - on training data only because that is our model\n",
    "#this takes a while to run. imagine it is running at least 9 combinations models with 3 folds and picking the best. Reduce parameters or folds if you want it to run faster\n",
    "pca_model = PCA(inputCol = \"scaledFeatures\", outputCol = \"pca_features_cv\")\n",
    "\n",
    "#create a randomforest classifier model to pass into pipeline\n",
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"pca_features_cv\")\n",
    "\n",
    "#creating a pipeline with the pca and model to use in the cross validator\n",
    "ppl_cv = Pipeline(stages = [pca_model, rf])\n",
    "\n",
    "\n",
    "#create a param grid to pass to cross validator \n",
    "#k --> number of principal components\n",
    "#number of treess in rf\n",
    "#need to add more later\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "  .addGrid(pca_model.k, [10, 20, 30]) \\\n",
    "  .addGrid(rf.numTrees, [20, 30, 50]) \\\n",
    "  .build()\n",
    "\n",
    "#passs the model with variosu combinations of the parameters and it will pick the best one. Using 3 folds to save time. Check seed=42.\n",
    "crossval = CrossValidator(estimator = ppl_cv,\\\n",
    "                                        estimatorParamMaps=paramGrid,\\\n",
    "                                        evaluator = MulticlassClassificationEvaluator(),\\\n",
    "                                        numFolds= 3,seed=42)\n",
    "\n",
    "\n",
    "#this is our best model - fit the training data\n",
    "cv_model = crossval.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7723960143219148, 0.7733325749792399, 0.7727217338656844, 0.7974568204660167, 0.8025227590273747, 0.8040922137339593, 0.8017722452652558, 0.8052520576819326, 0.8029655061557093]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 50},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 50},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_f75115576b9f', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_46a92114fd56', name='numTrees', doc='Number of trees to train (>= 1).'): 50},)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all the 9 model accuracies. The max one was picked as best\n",
    "avgMetricsGrid = cv_model.avgMetrics\n",
    "print(avgMetricsGrid)\n",
    "\n",
    "#https://tsmatz.github.io/azure-databricks-exercise/exercise04-hyperparams-tuning.html\n",
    "# View all results (accuracy) by each params - these can be converted to pretty tables in pandas later\n",
    "list(zip(cv_model.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and evaluate the model for accuracy\n",
    "predictions = cv_model.transform(test_data)\n",
    "evaluator= MulticlassClassificationEvaluator(labelCol = \"label\", metricName= \"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8103416571659741\n"
     ]
    }
   ],
   "source": [
    "#increased accuracy with binary flag\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without PCA but selective features and QQ variables dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References\n",
    "#https://awesomeopensource.com/project/adornes/spark_python_ml_examples\n",
    "#https://spark.apache.org/docs/latest/ml-tuning.html\n",
    "#https://sparkbyexamples.com/pyspark/pyspark-rename-dataframe-column/\n",
    "#https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\n",
    "#https://people.stat.sc.edu/haigang/sparkCaseStudy.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110",
   "language": "python",
   "name": "ds5110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
