{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import ArrayType, StructField, StructType, StringType, IntegerType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext\n",
    "# set up the session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"project\")\\\n",
    "        .config(\"spark.executor.memory\", \"100g\")\\\n",
    "        .getOrCreate()\n",
    "        \n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://udc-ba26-29c0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd528323890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sfs/qumulo/qhome/smn7ba/ds5110/project'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas too for visualizations\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 ms, sys: 2.54 ms, total: 4.98 ms\n",
      "Wall time: 4.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import mlLib libraries for classification\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder,TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data; Create a binary flag; rename columns; Drop if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 ms, sys: 2.6 ms, total: 4.93 ms\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import whole data from the census\n",
    "data = spark.read.csv('/project/ds5559/ds5110_project_snoo/acs_15_19_south.csv', inferSchema=\"true\", header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|EDUC_FLAG|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "|        1|\n",
      "|        0|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 3.56 ms, sys: 1.93 ms, total: 5.49 ms\n",
      "Wall time: 986 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#writing a user defined function to create a Educated or Not Flag - if EDUC>6 then it is 1 and if not 0\n",
    "#https://towardsdatascience.com/5-ways-to-add-a-new-column-in-a-pyspark-dataframe-4e75c2fd8c08\n",
    "def EDUCFunc(value):\n",
    "  if   value > 6: \n",
    "      return 1\n",
    "  else:\n",
    "      return 0\n",
    "\n",
    "#create the function to be applied and create a new column EDUC_FLAG\n",
    "udfsomefunc = F.udf(EDUCFunc, IntegerType())\n",
    "data = data.withColumn(\"EDUC_FLAG\", udfsomefunc(\"EDUC\"))\n",
    "#see sample data\n",
    "data.select('EDUC_FLAG').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 1.17 ms, total: 3.19 ms\n",
      "Wall time: 6.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#check the count for EDUC>6 or verify if flag was populated correctly\n",
    "data.filter(data.EDUC>6).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 ms, sys: 578 µs, total: 3.91 ms\n",
      "Wall time: 8.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2470127"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#Verify the flag count. Should match number above\n",
    "data.filter(data.EDUC_FLAG!=0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About data\n",
    "AMERICAN COMMUNITY SURVEY 2015-2019 5-YEAR SAMPLE <br>\n",
    "5-in-100 national random sample of the population <br>\n",
    "Contains all households and persons from the 1% ACS samples for 2015, 2016, 2017, 2018, and 2019 identifiable by year. <br>\n",
    "The data include persons in group quarters. <br>\n",
    "This is a weighted sample. <br>\n",
    "The smallest identifiable geographic unit is the PUMA, containing at least 100,000 persons. PUMAs do not cross state boundaries. <br>\n",
    "Users should read the FAQ on the multi-year data. <br>\n",
    "\n",
    "\n",
    "WHERE CAN I GET BETTER GEOGRAPHIC IDENTIFIERS? <br>\n",
    "The lowest unit of geography in the microdata files is still the PUMA. PUMAs contain at least 100,000 people. <br>\n",
    "Aggregate data (but not microdata) is currently available from the Census Bureau for geographic areas as small as block groups, but only for the entire 2005-2009 period. <br>\n",
    "\n",
    "\n",
    "PERNUM numbers all persons within each household consecutively in the order in which they appear on the original census or survey form. <br>\n",
    "When combined with SAMPLE and SERIAL, PERNUM uniquely identifies each person within the IPUMS. <br>\n",
    "\n",
    "MULTYEAR identifies the actual year of survey in multi-year ACS/PRCS samples. <br>\n",
    "\n",
    "<br>\n",
    "For example, the 3-year ACS and PRCS data files each include cases from three single-year files. <br>\n",
    "For these multi-year samples, the YEAR variable identifies the last year of data (2007 for the 2005-2007 3-year data; 2008 for the 2006-2008 data; and so on). <br>\n",
    "MULTYEAR gives the single-year sample from which the case was drawn (2005, 2006, or 2007 for the 2005-2007 3-year data; 2006, 2007, or 2008 for the 2006-2008 3-year data; and so on). <br>\n",
    "\n",
    "https://usa.ipums.org/usa/acs_multyr.shtml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 703 µs, sys: 824 µs, total: 1.53 ms\n",
      "Wall time: 45.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#renaming dependent variable to label because the classfier is not recognizing other names. Skip thsi if you are trying other classifiers\n",
    "\n",
    "df = data.withColumn(\"label\",data.EDUC_FLAG) \\\n",
    "      .drop(\"EDUC_FLAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving col names in case if we can use it later ot iterate or use the list for labels etc.\n",
    "cols = df.columns\n",
    "#spark.createDataFrame(cols,StringType()).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5965249, 206)\n"
     ]
    }
   ],
   "source": [
    "#displaying number of rows and columns in the data\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|MULTYEAR|\n",
      "+--------+\n",
      "|    2018|\n",
      "|    2015|\n",
      "|    2019|\n",
      "|    2016|\n",
      "|    2017|\n",
      "+--------+\n",
      "\n",
      "CPU times: user 1.88 ms, sys: 860 µs, total: 2.74 ms\n",
      "Wall time: 6.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#number of years in the data set\n",
    "df.select('MULTYEAR').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|MULTYEAR| count|\n",
      "+--------+------+\n",
      "|    2015|117141|\n",
      "|    2016|117882|\n",
      "|    2017|119767|\n",
      "|    2018|119761|\n",
      "|    2019|121997|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sampling data to use more effeciently; seed = 42\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.sampleBy.html\n",
    "#https://towardsdatascience.com/exploratory-data-analysis-eda-with-pyspark-on-databricks-e8d6529626b1\n",
    "#https://www.kaggle.com/tientd95/advanced-pyspark-for-exploratory-data-analysis\n",
    "sampled = df.sampleBy(\"MULTYEAR\", fractions={2015: 0.1, 2016: 0.1, 2017:0.1, 2018:0.1, 2019:0.1}, seed=42)\n",
    "sampled.groupBy(\"MULTYEAR\").count().orderBy(\"MULTYEAR\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhhtype_dict = {'0':'N/A',            '1': 'Married-couple family household',            '2': 'Male householder, no wife present',            '3': 'Female householder, no husband present',            '4': 'Male householder, living alone',            '5': 'Male householder, not living alone',            '6': 'Female householder, living alone',            '7': 'Female householder, not living alone',            '9': 'HHTYPE could not be determined'}\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map to create meanign ful table # wip\n",
    "'''\n",
    "hhtype_dict = {'0':'N/A',\\\n",
    "            '1': 'Married-couple family household',\\\n",
    "            '2': 'Male householder, no wife present',\\\n",
    "            '3': 'Female householder, no husband present',\\\n",
    "            '4': 'Male householder, living alone',\\\n",
    "            '5': 'Male householder, not living alone',\\\n",
    "            '6': 'Female householder, living alone',\\\n",
    "            '7': 'Female householder, not living alone',\\\n",
    "            '9': 'HHTYPE could not be determined'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) ).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|MULTYEAR|HHTYPE|count|\n",
      "+--------+------+-----+\n",
      "|2019    |1     |73194|\n",
      "|2019    |3     |14782|\n",
      "|2019    |6     |7962 |\n",
      "|2019    |4     |5680 |\n",
      "|2019    |2     |4338 |\n",
      "|2019    |5     |1489 |\n",
      "|2019    |7     |1249 |\n",
      "|2018    |1     |71736|\n",
      "|2018    |3     |14839|\n",
      "|2018    |6     |7782 |\n",
      "|2018    |4     |5600 |\n",
      "|2018    |2     |4378 |\n",
      "|2018    |5     |1541 |\n",
      "|2018    |7     |1280 |\n",
      "|2017    |1     |71065|\n",
      "|2017    |3     |15179|\n",
      "|2017    |6     |7732 |\n",
      "|2017    |4     |5502 |\n",
      "|2017    |2     |4087 |\n",
      "|2017    |5     |1627 |\n",
      "|2017    |7     |1217 |\n",
      "|2016    |1     |69943|\n",
      "|2016    |3     |15249|\n",
      "|2016    |6     |7804 |\n",
      "|2016    |4     |5353 |\n",
      "|2016    |2     |4034 |\n",
      "|2016    |5     |1471 |\n",
      "|2016    |7     |1308 |\n",
      "|2015    |1     |69494|\n",
      "|2015    |3     |15353|\n",
      "|2015    |6     |7832 |\n",
      "|2015    |4     |5316 |\n",
      "|2015    |2     |4008 |\n",
      "|2015    |5     |1526 |\n",
      "|2015    |7     |1159 |\n",
      "+--------+------+-----+\n",
      "\n",
      "CPU times: user 2.86 ms, sys: 2.97 ms, total: 5.83 ms\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "##aggregating counts by Year and HHtype for sampple dataset - add labels - convert to visualization\n",
    "#sampled_n = sampled.select('HHTYPE').rdd.map(lambda x: hhtype_dict.get(x) )\n",
    "#sampled.filter((sampled.HHTYPE!=0) & (sampled.HHTYPE!=9)).groupBy('MULTYEAR','HHTYPE').count()\\\n",
    "    #.orderBy('MULTYEAR','count', ascending=False).show(100,truncate=False)\n",
    "sampled.filter((sampled.HHTYPE!=0) & (sampled.HHTYPE!=9)).groupBy('MULTYEAR','HHTYPE').count()\\\n",
    "    .orderBy('MULTYEAR','count', ascending=False).show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MULTYEAR: integer (nullable = true)\n",
      " |-- SAMPLE: integer (nullable = true)\n",
      " |-- SERIAL: integer (nullable = true)\n",
      " |-- CBSERIAL: long (nullable = true)\n",
      " |-- HHWT: double (nullable = true)\n",
      " |-- HHTYPE: integer (nullable = true)\n",
      " |-- CLUSTER: long (nullable = true)\n",
      " |-- REGION: integer (nullable = true)\n",
      " |-- STATEFIP: integer (nullable = true)\n",
      " |-- COUNTYFIP: integer (nullable = true)\n",
      " |-- METRO: integer (nullable = true)\n",
      " |-- STRATA: integer (nullable = true)\n",
      " |-- GQ: integer (nullable = true)\n",
      " |-- OWNERSHP: integer (nullable = true)\n",
      " |-- OWNERSHPD: integer (nullable = true)\n",
      " |-- MORTGAGE: integer (nullable = true)\n",
      " |-- TAXINCL: integer (nullable = true)\n",
      " |-- INSINCL: integer (nullable = true)\n",
      " |-- PROPINSR: integer (nullable = true)\n",
      " |-- COSTELEC: integer (nullable = true)\n",
      " |-- COSTGAS: integer (nullable = true)\n",
      " |-- COSTWATR: integer (nullable = true)\n",
      " |-- COSTFUEL: integer (nullable = true)\n",
      " |-- FOODSTMP: integer (nullable = true)\n",
      " |-- VALUEH: integer (nullable = true)\n",
      " |-- FRIDGE: integer (nullable = true)\n",
      " |-- CINETHH: integer (nullable = true)\n",
      " |-- CILAPTOP: integer (nullable = true)\n",
      " |-- CISMRTPHN: integer (nullable = true)\n",
      " |-- CITABLET: integer (nullable = true)\n",
      " |-- CIDATAPLN: integer (nullable = true)\n",
      " |-- CIHISPEED: integer (nullable = true)\n",
      " |-- CISAT: integer (nullable = true)\n",
      " |-- CIDIAL: integer (nullable = true)\n",
      " |-- CIOTHSVC: integer (nullable = true)\n",
      " |-- FUELHEAT: integer (nullable = true)\n",
      " |-- VEHICLES: integer (nullable = true)\n",
      " |-- COUPLETYPE: integer (nullable = true)\n",
      " |-- SSMC: integer (nullable = true)\n",
      " |-- NFAMS: integer (nullable = true)\n",
      " |-- NSUBFAM: integer (nullable = true)\n",
      " |-- NCOUPLES: integer (nullable = true)\n",
      " |-- NMOTHERS: integer (nullable = true)\n",
      " |-- NFATHERS: integer (nullable = true)\n",
      " |-- MULTGEN: integer (nullable = true)\n",
      " |-- MULTGEND: integer (nullable = true)\n",
      " |-- QCOSTELE: integer (nullable = true)\n",
      " |-- QCOSTFUE: integer (nullable = true)\n",
      " |-- QCOSTGAS: integer (nullable = true)\n",
      " |-- QCOSTWAT: integer (nullable = true)\n",
      " |-- QFOODSTM: integer (nullable = true)\n",
      " |-- QINSINCL: integer (nullable = true)\n",
      " |-- QMORTGAG: integer (nullable = true)\n",
      " |-- QOWNERSH: integer (nullable = true)\n",
      " |-- QPROPINS: integer (nullable = true)\n",
      " |-- QTAXINCL: integer (nullable = true)\n",
      " |-- QVALUEH: integer (nullable = true)\n",
      " |-- QFUELHEA: integer (nullable = true)\n",
      " |-- QCIDIAL: integer (nullable = true)\n",
      " |-- QCILAPTOP: integer (nullable = true)\n",
      " |-- QCINETHH: integer (nullable = true)\n",
      " |-- QCIOTHSVC: integer (nullable = true)\n",
      " |-- QCISAT: integer (nullable = true)\n",
      " |-- QCISMRTPHN: integer (nullable = true)\n",
      " |-- QCITABLET: integer (nullable = true)\n",
      " |-- QCIDATAPLN: integer (nullable = true)\n",
      " |-- QVEHICLE: integer (nullable = true)\n",
      " |-- RESPMODE: integer (nullable = true)\n",
      " |-- PERNUM: integer (nullable = true)\n",
      " |-- PERWT: double (nullable = true)\n",
      " |-- RELATE: integer (nullable = true)\n",
      " |-- RELATED: integer (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARST: integer (nullable = true)\n",
      " |-- BIRTHYR: integer (nullable = true)\n",
      " |-- MARRNO: integer (nullable = true)\n",
      " |-- YRMARR: integer (nullable = true)\n",
      " |-- RACE: integer (nullable = true)\n",
      " |-- RACED: integer (nullable = true)\n",
      " |-- HISPAN: integer (nullable = true)\n",
      " |-- HISPAND: integer (nullable = true)\n",
      " |-- BPL: integer (nullable = true)\n",
      " |-- BPLD: integer (nullable = true)\n",
      " |-- CITIZEN: integer (nullable = true)\n",
      " |-- YRNATUR: integer (nullable = true)\n",
      " |-- YRIMMIG: integer (nullable = true)\n",
      " |-- YRSUSA1: integer (nullable = true)\n",
      " |-- RACAMIND: integer (nullable = true)\n",
      " |-- RACASIAN: integer (nullable = true)\n",
      " |-- RACBLK: integer (nullable = true)\n",
      " |-- RACPACIS: integer (nullable = true)\n",
      " |-- RACWHT: integer (nullable = true)\n",
      " |-- RACOTHER: integer (nullable = true)\n",
      " |-- HCOVANY: integer (nullable = true)\n",
      " |-- HCOVPRIV: integer (nullable = true)\n",
      " |-- HINSEMP: integer (nullable = true)\n",
      " |-- HINSPUR: integer (nullable = true)\n",
      " |-- HINSTRI: integer (nullable = true)\n",
      " |-- HCOVPUB: integer (nullable = true)\n",
      " |-- HINSCAID: integer (nullable = true)\n",
      " |-- HINSCARE: integer (nullable = true)\n",
      " |-- HINSVA: integer (nullable = true)\n",
      " |-- HINSIHS: integer (nullable = true)\n",
      " |-- SCHOOL: integer (nullable = true)\n",
      " |-- EDUC: integer (nullable = true)\n",
      " |-- EDUCD: integer (nullable = true)\n",
      " |-- GRADEATT: integer (nullable = true)\n",
      " |-- GRADEATTD: integer (nullable = true)\n",
      " |-- SCHLTYPE: integer (nullable = true)\n",
      " |-- DEGFIELD: integer (nullable = true)\n",
      " |-- DEGFIELDD: integer (nullable = true)\n",
      " |-- DEGFIELD2: integer (nullable = true)\n",
      " |-- DEGFIELD2D: integer (nullable = true)\n",
      " |-- EMPSTAT: integer (nullable = true)\n",
      " |-- EMPSTATD: integer (nullable = true)\n",
      " |-- LABFORCE: integer (nullable = true)\n",
      " |-- CLASSWKR: integer (nullable = true)\n",
      " |-- CLASSWKRD: integer (nullable = true)\n",
      " |-- OCC: integer (nullable = true)\n",
      " |-- IND: integer (nullable = true)\n",
      " |-- UHRSWORK: integer (nullable = true)\n",
      " |-- LOOKING: integer (nullable = true)\n",
      " |-- AVAILBLE: integer (nullable = true)\n",
      " |-- INCTOT: integer (nullable = true)\n",
      " |-- FTOTINC: integer (nullable = true)\n",
      " |-- INCWAGE: integer (nullable = true)\n",
      " |-- INCBUS00: integer (nullable = true)\n",
      " |-- INCSS: integer (nullable = true)\n",
      " |-- INCWELFR: integer (nullable = true)\n",
      " |-- INCINVST: integer (nullable = true)\n",
      " |-- INCRETIR: integer (nullable = true)\n",
      " |-- INCSUPP: integer (nullable = true)\n",
      " |-- INCOTHER: integer (nullable = true)\n",
      " |-- INCEARN: integer (nullable = true)\n",
      " |-- POVERTY: integer (nullable = true)\n",
      " |-- OCCSCORE: integer (nullable = true)\n",
      " |-- SEI: integer (nullable = true)\n",
      " |-- HWSEI: double (nullable = true)\n",
      " |-- VETSTAT: integer (nullable = true)\n",
      " |-- VETSTATD: integer (nullable = true)\n",
      " |-- VET01LTR: integer (nullable = true)\n",
      " |-- PWSTATE2: integer (nullable = true)\n",
      " |-- PWCOUNTY: integer (nullable = true)\n",
      " |-- PWTYPE: integer (nullable = true)\n",
      " |-- PWPUMA00: integer (nullable = true)\n",
      " |-- TRANWORK: integer (nullable = true)\n",
      " |-- CARPOOL: integer (nullable = true)\n",
      " |-- RIDERS: integer (nullable = true)\n",
      " |-- TRANTIME: integer (nullable = true)\n",
      " |-- DEPARTS: integer (nullable = true)\n",
      " |-- ARRIVES: integer (nullable = true)\n",
      " |-- GCHOUSE: integer (nullable = true)\n",
      " |-- GCMONTHS: integer (nullable = true)\n",
      " |-- GCRESPON: integer (nullable = true)\n",
      " |-- QAGE: integer (nullable = true)\n",
      " |-- QMARRNO: integer (nullable = true)\n",
      " |-- QMARST: integer (nullable = true)\n",
      " |-- QRELATE: integer (nullable = true)\n",
      " |-- QSEX: integer (nullable = true)\n",
      " |-- QYRMARR: integer (nullable = true)\n",
      " |-- QBPL: integer (nullable = true)\n",
      " |-- QCITIZEN: integer (nullable = true)\n",
      " |-- QHISPAN: integer (nullable = true)\n",
      " |-- QRACE: integer (nullable = true)\n",
      " |-- QYRNATUR: integer (nullable = true)\n",
      " |-- QHINSEMP: integer (nullable = true)\n",
      " |-- QHINSPUR: integer (nullable = true)\n",
      " |-- QHINSTRI: integer (nullable = true)\n",
      " |-- QHINSCAI: integer (nullable = true)\n",
      " |-- QHINSCAR: integer (nullable = true)\n",
      " |-- QHINSVA: integer (nullable = true)\n",
      " |-- QHINSIHS: integer (nullable = true)\n",
      " |-- QEDUC: integer (nullable = true)\n",
      " |-- QGRADEAT: integer (nullable = true)\n",
      " |-- QDEGFIELD: integer (nullable = true)\n",
      " |-- QSCHOOL: integer (nullable = true)\n",
      " |-- QCLASSWK: integer (nullable = true)\n",
      " |-- QEMPSTAT: integer (nullable = true)\n",
      " |-- QIND: integer (nullable = true)\n",
      " |-- QOCC: integer (nullable = true)\n",
      " |-- QUHRSWOR: integer (nullable = true)\n",
      " |-- QINCEARN: integer (nullable = true)\n",
      " |-- QINCBUS: integer (nullable = true)\n",
      " |-- QINCINVS: integer (nullable = true)\n",
      " |-- QINCOTHE: integer (nullable = true)\n",
      " |-- QINCRETI: integer (nullable = true)\n",
      " |-- QINCSS: integer (nullable = true)\n",
      " |-- QINCSUPP: integer (nullable = true)\n",
      " |-- QINCTOT: integer (nullable = true)\n",
      " |-- QFTOTINC: integer (nullable = true)\n",
      " |-- QINCWAGE: integer (nullable = true)\n",
      " |-- QINCWELF: integer (nullable = true)\n",
      " |-- QVETSTAT: integer (nullable = true)\n",
      " |-- QCARPOOL: integer (nullable = true)\n",
      " |-- QDEPARTS: integer (nullable = true)\n",
      " |-- QPWSTAT2: integer (nullable = true)\n",
      " |-- QRIDERS: integer (nullable = true)\n",
      " |-- QTRANTIM: integer (nullable = true)\n",
      " |-- QTRANWOR: integer (nullable = true)\n",
      " |-- QGCHOUSE: integer (nullable = true)\n",
      " |-- QGCMONTH: integer (nullable = true)\n",
      " |-- QGCRESPO: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data; Scale; PCA; RF Classification - seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    1|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 6.95 ms, sys: 6.3 ms, total: 13.3 ms\n",
      "Wall time: 4.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pass all the features into vector assembler to create a vector format to pass tto the classification model\n",
    "assembler = VectorAssembler(inputCols=[cols for cols in cols if cols!='label'], outputCol=\"features\") \n",
    "transformed = assembler.transform(sampled)\n",
    "#register table as sql table and keep only columns fo interest and save in a new dataframe. This can be done without using SQl as well.\n",
    "transformed.registerTempTable('transformed_tbl')\n",
    "transformed_df = sqlContext.sql('select label,features from transformed_tbl')\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 937 µs, sys: 1.05 ms, total: 1.99 ms\n",
      "Wall time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#splitting data before preprocessing will stop leakage\n",
    "#randomly split data\n",
    "training_data, test_data = transformed_df.randomSplit([0.7, 0.3], seed=42)\n",
    "cached_tr = training_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.83 ms, sys: 1.46 ms, total: 9.3 ms\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#scale the data\n",
    "scaler_train = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel_train = scaler_train.fit(cached_tr)\n",
    "scaledData_train = scalerModel_train.transform(cached_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|      scaledFeatures|\n",
      "+-----+--------------------+\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "|    0|(205,[0,1,2,3,4,5...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "CPU times: user 1.03 ms, sys: 1.13 ms, total: 2.17 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#check sample scaled data\n",
    "scaledData_train.select(\"label\",\"scaledFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 397 ms, total: 1.49 s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#pca to reduce 200 odd features into principal components - on training data only because that is our model\n",
    "#this takes a while to run. imagine it is running at least 9 combinations models with 3 folds and picking the best. Reduce parameters or folds if you want it to run faster\n",
    "pca_model = PCA(inputCol = \"scaledFeatures\", outputCol = \"pca_features_cv\")\n",
    "\n",
    "#create a randomforest classifier model to pass into pipeline\n",
    "rf = RandomForestClassifier(labelCol = \"label\", featuresCol = \"pca_features_cv\")\n",
    "\n",
    "#creating a pipeline with the pca and model to use in the cross validator\n",
    "ppl_cv = Pipeline(stages = [pca_model, rf])\n",
    "\n",
    "\n",
    "#create a param grid to pass to cross validator \n",
    "#k --> number of principal components\n",
    "#number of treess in rf\n",
    "#need to add more later\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "  .addGrid(pca_model.k, [10, 20, 30]) \\\n",
    "  .addGrid(rf.numTrees, [20, 30, 50]) \\\n",
    "  .build()\n",
    "\n",
    "#passs the model with variosu combinations of the parameters and it will pick the best one. Using 3 folds to save time. Check seed=42.\n",
    "crossval = CrossValidator(estimator = ppl_cv,\\\n",
    "                                        estimatorParamMaps=paramGrid,\\\n",
    "                                        evaluator = MulticlassClassificationEvaluator(),\\\n",
    "                                        numFolds= 3,seed=42)\n",
    "\n",
    "\n",
    "#this is our best model - fit the training data\n",
    "cv_model = crossval.fit(scaledData_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773276344611239, 0.7734615740708852, 0.7735542859352948, 0.8041363061371772, 0.8039156300327328, 0.8054776937147163, 0.8031545556633992, 0.8038459555606521, 0.8053134868761425]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 10,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 50},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 20,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 50},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 20},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 30},),\n",
       " ({Param(parent='PCA_4bb6a73e0377', name='k', doc='the number of principal components'): 30,\n",
       "   Param(parent='RandomForestClassifier_cc3bed092c3d', name='numTrees', doc='Number of trees to train (>= 1).'): 50},)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all the 9 model accuracies. The max one was picked as best\n",
    "avgMetricsGrid = cv_model.avgMetrics\n",
    "print(avgMetricsGrid)\n",
    "\n",
    "#https://tsmatz.github.io/azure-databricks-exercise/exercise04-hyperparams-tuning.html\n",
    "#https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html\n",
    "# View all results (accuracy) by each params - these can be converted to pretty tables in pandas later\n",
    "list(zip(cv_model.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale test data\n",
    "scaler_test = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel_test = scaler_test.fit(test_data)\n",
    "scaledData_test = scalerModel_test.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.5 ms, sys: 6.01 ms, total: 26.5 ms\n",
      "Wall time: 26.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#predict and evaluate the model for accuracy\n",
    "predictions = cv_model.transform(scaledData_test)\n",
    "evaluator= MulticlassClassificationEvaluator(labelCol = \"label\", metricName= \"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7986235652797704\n"
     ]
    }
   ],
   "source": [
    "#increased accuracy with binary flag\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix, threshold, roc and other fun stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##more to come"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model without PCA but selective features and QQ variables dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#References\n",
    "#https://awesomeopensource.com/project/adornes/spark_python_ml_examples\n",
    "#https://spark.apache.org/docs/latest/ml-tuning.html\n",
    "#https://sparkbyexamples.com/pyspark/pyspark-rename-dataframe-column/\n",
    "#https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\n",
    "#https://people.stat.sc.edu/haigang/sparkCaseStudy.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5110",
   "language": "python",
   "name": "ds5110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
